{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zacharypangan/AgentNetworkSimulation/blob/main/Copy_of_lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gzGQkHDH0Ls"
      },
      "source": [
        "*Since the resources on Google Colab are limited, you may bump into limitations when trying to use it for your own project. In this case, copy this notebook on your computational plateform to use it with your own GPU.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMiKSpCZn6C7"
      },
      "source": [
        "## Enabling GPU\n",
        "\n",
        "The package requires a GPU to run. To enable a GPU for this Notebook, you will need to:  \n",
        "- Click 'Edit' in the menu bar, then click 'Notebook Settings'.\n",
        "- Select GPU from the Hardware Accelerator drop-down list, then click 'Save'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypehq4bLqfMI"
      },
      "source": [
        "*Click* on the arrow below to verify that you are successfully connected to a GPU. This should return the name of the GPU used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY2lchdVmv6M"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "\n",
        "cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgO-mb9Tm-Sg"
      },
      "source": [
        "# **Lab 1: The python package *AugmentedSocialScientist***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfxnJGERrBlw"
      },
      "source": [
        "## Installing the package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I4betrWr-DS"
      },
      "source": [
        "Run the cell below to install the package *AugmentedSocialScientist* on the current Google Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WW5Eu_Sq6-w"
      },
      "outputs": [],
      "source": [
        "!pip install AugmentedSocialScientist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkQVqqazTNa_"
      },
      "source": [
        "Import BERT model ([Devlin et al. 2019](https://arxiv.org/pdf/1810.04805.pdf)) from the package *AugmentedSocialScientist*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ1h8TBe5Hwp"
      },
      "outputs": [],
      "source": [
        "from AugmentedSocialScientist import bert"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The module `bert` contains 3 main functions:\n",
        "- `bert.encode()` to preprocess the data;\n",
        "- `bert.run_training()` to train, validate and save a model;\n",
        "- `bert.predict_with_model()`  to make predictions with a saved model."
      ],
      "metadata": {
        "id": "6YBlo4SMhihh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab session, we will use a classic text classification task -- clickbait detection -- to illustrate the use of these functions."
      ],
      "metadata": {
        "id": "kBUAexeWik5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **N.B.**\n",
        ">\n",
        "> BERT is a pre-trained language model for the English language. Our package also contains models for other languages:\n",
        "> - `camembert` for French;\n",
        "> - `german_bert` for German;\n",
        "> - `spanish_bert` for Spanish;\n",
        "> - `xlmroberta` which is a multi-lingual model supporting 100 languages.\n",
        "> To use them, simply import the corresponding model and replace `bert` with the name of the imported model.\n",
        ">\n",
        "> For example, to use the French language model `camembert`:\n",
        "> 1. Import the model `camembert`:\n",
        "```python\n",
        "from AugmentedSocialScientist import camembert\n",
        "```\n",
        "> 2. Then use the functions `camembert.encode()`, `camembert.run_training()`, `camembert.predict_with_model()`.\n",
        ">\n",
        "> The source code of the package can be found here: https://github.com/rubingshen/AugmentedSocialScientist"
      ],
      "metadata": {
        "id": "kN1WpFDninET"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSkhiUswsfq-"
      },
      "source": [
        "# **Example: Clickbait Detection**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZtF0dlDTlf_"
      },
      "source": [
        "For this example, we use data from [Chakraborty et al. 2016](https://github.com/bhargaviparanjape/clickbait), in order to train a classifier that distinguishes between clickbait and non-clickbait headlines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAYGr0bu1hLq"
      },
      "source": [
        "Import other required packages for this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC-u-MSHrqId"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.options.display.max_colwidth=None\n",
        "pd.options.display.max_rows=100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofb8XY-E4sNK"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9siPlPKsYHn"
      },
      "outputs": [],
      "source": [
        "cb_train = pd.read_csv('https://raw.githubusercontent.com/rubingshen/AugmentedSocialScientist/main/datasets/english/clickbait_train.csv')\n",
        "cb_test = pd.read_csv('https://raw.githubusercontent.com/rubingshen/AugmentedSocialScientist/main/datasets/english/clickbait_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cb_train"
      ],
      "metadata": {
        "id": "PvG--w7nIqL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb_test"
      ],
      "metadata": {
        "id": "ftHD_9HsIsQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model"
      ],
      "metadata": {
        "id": "GRFjgQ8pdV1f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR5GNF5g47Nq"
      },
      "source": [
        "### Step 1: Preprocessing the data with the function `bert.encode()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_8LpXth5A_M"
      },
      "source": [
        "The function `bert.encode(sentences, labels)` will preprocess the training and test data and convert them to pytorch's *dataloader* object, a format readable by the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function takes two arguments: a list of texts and a list of corresponding labels."
      ],
      "metadata": {
        "id": "X-aqyBkiLIhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**⚠️ For technical reasons, the labels must be integers starting from 0 (0, 1, 2...)**"
      ],
      "metadata": {
        "id": "0KSF7PR5hK6j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16YIbp074c_F"
      },
      "outputs": [],
      "source": [
        "train_dataloader = bert.encode(cb_train.headline, cb_train.is_clickbait)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mGF4dbO4fHZ"
      },
      "outputs": [],
      "source": [
        "test_dataloader = bert.encode(cb_test.headline, cb_test.is_clickbait)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Training a model with the function `bert.run_training()`"
      ],
      "metadata": {
        "id": "yBL_-U3sKUOu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN7PITHJ5y1j"
      },
      "source": [
        "The function `bert.run_training()` trains, validates, and saves the fine-tuned BERT model. It takes the following argument:\n",
        "\n",
        "* `training_dataloader`: the preprocessed training set;\n",
        "* `test_dataloader`: the preprocessed test set;\n",
        "* `n_epochs`: the number of epochs;\n",
        "* `lr`: the learning rate;\n",
        "* `random_state`: the fixed random state (for replicability purposes).\n",
        "* `save_model_as`: the name of model saving folder. The model will be saved at `./models/<model_name>`. If you don't want to save the model after training, set this parameter to `None`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model has completed its training phase, it calculates the F1-score (between 0 and 1) to assess the quality of the model."
      ],
      "metadata": {
        "id": "td3L4yHILhmf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEZRDH415dpm"
      },
      "outputs": [],
      "source": [
        "score = bert.run_training(train_dataloader,\n",
        "                          test_dataloader,\n",
        "                          n_epochs=2,\n",
        "                          lr=5e-5,\n",
        "                          random_state=42,\n",
        "                          save_model_as='clickbait')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "id": "mNAujP7onAgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting on new data"
      ],
      "metadata": {
        "id": "UsyEBkgjdbVu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCIZqypcQDBl"
      },
      "source": [
        "Load unlabelled data that we would like to automatically label using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq005kyD6T33"
      },
      "outputs": [],
      "source": [
        "cb_pred = pd.read_csv('https://raw.githubusercontent.com/rubingshen/AugmentedSocialScientist/main/datasets/english/clickbait_pred.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkrxKeIB6b00"
      },
      "outputs": [],
      "source": [
        "cb_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ4btOGQ6WUu"
      },
      "source": [
        "### Step 1: Preprocessing the data with the function `bert.encode()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fY5JUvn6kbJ"
      },
      "source": [
        "Preprocess the prediction data with the function `bert.encode()` by inputing only the list of texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhUhJRbm6dEa"
      },
      "outputs": [],
      "source": [
        "pred_dataloader = bert.encode(cb_pred.headline)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Automatic annotation with `bert.predict_with_model()`"
      ],
      "metadata": {
        "id": "WdTTGgM4drMx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2WKW4vu6t1T"
      },
      "source": [
        "Use the function `bert.predict_with_model()` to make predictions on the data with the trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function takes two arguments:\n",
        "\n",
        "* `pred_dataloader`: the preprocessed prediction data;\n",
        "* `model_path`: the path of saved model to be used for prediction."
      ],
      "metadata": {
        "id": "BfFZECcnM26p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0g0H9m86qSY"
      },
      "outputs": [],
      "source": [
        "pred_proba = bert.predict_with_model(pred_dataloader, model_path='./models/clickbait')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfyqdymUJqGe"
      },
      "source": [
        "Output: the model returns the probabiliby of each headline in the unlabelled data set to belong to a given category (0: not clickbait; 1: clickbait)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4hTChFaI_rJ"
      },
      "outputs": [],
      "source": [
        "pred_proba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unAhVKOUJ10k"
      },
      "source": [
        "Store the predicted category and probability to the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTzIp-IbJZff"
      },
      "outputs": [],
      "source": [
        "cb_pred['pred_label'] = np.argmax(pred_proba, axis=1)\n",
        "cb_pred['pred_proba'] = np.max(pred_proba, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cb_pred"
      ],
      "metadata": {
        "id": "F7USnSzONZL6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}